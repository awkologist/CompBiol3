{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Biology\n",
    "## A Practical Introduction to Bio Data Juggling with Worked Examples\n",
    "### Author: Röbbe Wünschiers, March 2025\n",
    "\n",
    "This extensively expanded third edition offers a practical introduction to Bio Data Science. With a hands-on approach to learning, this book offers ample opportunities to practice:\n",
    "\n",
    "- Installing and utilizing Linux as a virtual machine or remotely\n",
    "- Processing bio data with the programming language AWK\n",
    "- Managing data with the relational database system MariaDB\n",
    "- Analyzing and visualizing data with R\n",
    "- Implementing good bioinformatics practices with Jupyter Notebook and GitHub\n",
    "\n",
    "This book targets both students and professionals in the life sciences. While it is aimed at beginners, it also provides valuable tips and tricks for experienced researchers dealing with large datasets. \n",
    "\n",
    "Worked examples illustrate how to utilize various bioinformatics tools such as BLAST, Clustal, PLINK, IGV, SAMtools, BCFtools, Mason2, Minimap, NCBI Datasets, Velvet, Jmol, and more for:\n",
    "\n",
    "- Identifying bacterial proteins potentially associated with pathogenicity\n",
    "- Querying molecular structures for redox-regulated enzymes\n",
    "- Mapping and assembling real or simulated sequence reads\n",
    "- Identifying and mapping molecular structure mutations in viruses\n",
    "- Conducting genome-wide association studies\n",
    "\n",
    "All software tools and datasets mentioned are freely available, and all code is accessible as Jupyter Notebooks on GitHub. Drawing from the author's experiences and knowledge gained from both academia and industry, this book provides a practical and comprehensive approach to bioinformatics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART I – Whetting Your Appetite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 01 – Introduction\n",
    "This chapter gives a short historical introduction to bioinformatics and computational biology and compares both disciplines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 02 – Content of this Book\n",
    "This chapter sketches the main topics of this book, namely shell programming, Sed, AWK, MariaDB and R. It also describes the conventions and prerequisites for working with this book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART II – Learning and Setting Up Our Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 03 – The World of Linux\n",
    "In this chapter we are setting up our playground: A running Linux system. But you should first get an idea of what operating systems in general and Linux in particular are. It is not absolutely necessary to know all of this. However, since you will be working with Linux, you will be part of its history! I think you should know (and appreciate) the basics of this history. Then, you will learn some of the ways you can run Linux on your computer or connect to a Linux server. So this chapter is the foundation for all the other chapters. Finally, you will see how easy it is to install software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART III – Working with Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 04 – The First Touch\n",
    " In this chapter you will learn the basics of working with Linux: Logging in, executing commands and using the command line, logging out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 05 – Working with Files\n",
    "\n",
    "This chapter introduces you to working with files and directories in the Linux world. Among other things, it also shows how to deal with file archives, how to search for files and what the individual file attributes mean. You also learn how to download data from the internet via the terminal.\n",
    "\n",
    "&#11157; [Open bashtrash.ipynb](05_TheBash/bashtrash.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 06 – Remote Connections\n",
    "Remote working has prevailed for one reason or another. Most likely you will execute resource-consuming data processing at a remote Linux server. There are a lot of tools to be productive and efficient remotely. This chapter shows how to exchange data with your client computer and keep programs running once you exit a remote connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 07 – Playing with Text and Data Files\n",
    "\n",
    "How to look at gigabyte large text files? How to extract relevant or unique lines? How to compare text files? And, how to edit them? This chapter introduces basic command line tools and introduces you to the powerful Vim text editor.\n",
    "\n",
    "&#11157; [Open textedit.ipynb](07_TextEdit/textedit.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Chapter 08 – Get More Out of the Shell\n",
    "\n",
    "The power of Linux lies in its shell. Pipes, redirections, functions, wildcards, batch jobs, scheduled commands? Playing with processes? This chapter introduces you to the power of the Bash shell.\n",
    "\n",
    "&#11157; [Open shelluse.ipynb](08_ShellUse/shelluse.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 09 – Installing BLAST+ and ClustalW\n",
    "In this chapter you will learn how to install small programs manually. As examples, we are using BLAST+ (Basic Local Alignment Search Tool) and\n",
    "ClustalW. BLAST+ is a powerful tool to find sequences in a database. ClustalW is a general-purpose multiple-sequence alignment program for nucleic acid or protein sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART IV – Processing and Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 10 – Shell Programming\n",
    "\n",
    "With this chapter we enter a new world. Up to now, you processed files by executing a number of commands. From now on, we are going to put commands together, blend them with some logic and write our first shell scripts this way. IF you work through this chapter THEN you know basic programming techniques. Hello World!\n",
    "\n",
    "&#11157; &#11157; [Open shellprg.ipynb](10_ShellPrg/shellprg.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 11 – Regular Expressions\n",
    "\n",
    "Regular expressions are extremely useful and I cannot overemphasize the word \"extremely\". Regular expressions provide a brief, flexible and comprehensive way to specify or recognize text strings, e.g. character patterns. They are available in virtually all Linux tools and programming languages. A must read chapter.\n",
    "\n",
    "&#11157; &#11157; [Open regex.ipynb](11_RegEx/regex.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 12 – Stream Editor Sed\n",
    "\n",
    "The stream editor Sed is a non-interactive, line-oriented, stream editor. It emerges as a powerful tool in computational biology due to its versatile text processing capabilities. This chapter introduces you to its ability to perform complex pattern matching and substitution tasks, which you can apply on largescale datasets. Sed is perfect for data pre-processing, format conversion and text manipulation, facilitating the extraction of relevant information from biological datasets. Moreover, its seamless integration with shell scripting allows for automation of repetitive tasks, enhancing productivity in computational biology workflows.\n",
    "\n",
    "&#11157; [Open sed.ipynb](12_Sed/sed.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 13 – Data Processing with AWK\n",
    "\n",
    "AWK is a great language for both learning programming and processing text-based data files. Ninety-nine per cent of the time you will be working with text-based files, be it data tables, omic data or whatever. Apart from being simple to learn and having a clear syntax, AWK provides you with the possibility to construct your own commands. Thus, the language may grow with you as you grow with the language. Hello World, again. This chapter closes with an example of how to measure sequence distances by dynamic programming. With the basic knowledge of AWK presented in this chapter you are well prepared to master large-scale data processing and to learn any other programming language, if you feel to do so.\n",
    "\n",
    "&#11157; [Open awk.ipynb](13_AWK/awk.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 14 – Other Programming Languages\n",
    "\n",
    "Every book needs a short chapter – this is mine. It describes why it is a good way to learn programming with Python or Julia next. And it shows how, e.g., PHP and HTML can help to disseminate data processing pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART V – Advanced Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 15 – GitHub Repositories and Jupyter Notebooks\n",
    "Abstract This chapter introduces two valuable tools widely utilized in computational biology: GitHub and Jupyter Notebooks. GitHub provides a robust environment for managing project data, offering features for backup, dissemination and collaboration. You can organize your projects within folders and files, selecting specific items for backup, and create a versioned history of your project. This versioning system allows for easy rollback to earlier states, ensuring data integrity. Jupyter Notebooks, on the other hand, offer a flexible platform for combining programming code and documentation within a web browser interface. These notebooks facilitate collaboration by enabling easy exchange of files among collaborators, allowing recipients to execute all code contained within the notebook. This feature-rich environment enhances reproducibility and transparency in computational biology research by providing a unified platform for code execution and documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 16 – Relational Databases with MariaDB\n",
    "\n",
    "This chapter introduces you to the heart of data management, namely, the databases. It will introduce you to MariaDB, an open-source relational database management system. Relational essentially means that your data is organized in tables that are related to each other. With its SQL-based query language, it provides a powerful platform for storing, retrieving, and analyzing biological data. Its ability to handle large-scale datasets and complex relationships makes it well suited for a wide range of bioinformatics applications, including genomics, proteomics, and metabolomics. MariaDB’s active community and extensive documentation provide valuable resources for you to leverage its capabilities in you projects. In summary, MariaDB emerges as a versatile and scalable database solution for computational biologists, oﬀering robust features and performance for managing and analyzing biological data eﬀectively.\n",
    "\n",
    "&#11157; [Open mariadb.ipynb](16_MariaDB/mariadb.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 17 – The Statistics Suite R\n",
    "\n",
    "Data analysis commonly involves visualization of data. This includes both plotting the data themselves and plotting properties of the dataset like frequencies of certain numbers. R is a very well established platform for scientists in general and computational biologists in particular. Besides from being a programming environment for statistical computing, R is also a data visualization tool. Several topic specific packages are available to analyze and visualize experimental data, e.g. for evolutionary biology, the evaluation of biochemical assays, nucleotide and amino acid sequence analysis, microarray data interpretation and more. This chapter provides a basic introduction, exemplifies statistical data analysis, demonstrates installation of additional packages and shows how to retrieve data from a MariaDB or MySQL database. \n",
    "\n",
    "&#11157; [Open rstudio.ipynb](17_RStudio/rstudio.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART VI – Worked Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 18 – BLASTing Forensic PCR Primers\n",
    "\n",
    "In this project, our aim is to query CODIS primer sequences within the human genome. CODIS, or the Combined DNA Index System, is a program in the United States utilized for law enforcement purposes, aiding in crime-solving by identifying and linking DNA evidence. Forensic laboratories contribute and compare DNA profiles electronically at various levels: the Local DNA Index System (LDIS), the State DNA Index System (SDIS), and the National DNA Index System (NDIS). We will be conducting BLAST+ searches with CODIS primer sequences against several human genomic sequences, including the human reference genome, a Caucasian individual for the Ashkenazi Human Reference Genome project, and a female Sumatran orangutan. With the virtual PCR amplicons, we will proceed to create a multiple sequence alignment and generate a guide tree. The guide tree is computed from the distance matrix generated from pairwise alignment scores. We are going to use Clustal Omega to perform the alignment and NJplot to visualize the resulting phylogenetic tree.\n",
    "\n",
    "&#11157; [Open primerblast.ipynb](18_PrimerBlast/primerblast.ipynb)  \n",
    "&#11157; [Open remote-primerblast.ipynb](18_PrimerBlast/remote-primerblast.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 19 – In Search of Diﬀerences in Proteomes\n",
    "\n",
    "This project introduces two serotypes of Escherichia coli: one pathogenic and one non-pathogenic variety. The serotype O157 –H7 emerges as a significant cause of foodborne illness, notably linked to undercooked meat since its detection in 1982. Phylogenetic analyses suggest that O157 –H7 diverged from a common ancestor around 4.5 million years ago, acquiring its pathogenicity possibly through horizontal gene transfer. Can we identify proteins associated with pathogenicity among those acquired genes? To answer this question, we compare the translated, annotated genomes of one non-pathogenic and one pathogenic serotype. This project aims to uncover the presence of diﬀerent genes in different but related genomes. Central to this analysis is the Basic Local Alignment Search Tool (BLAST+) that we run locally and in the terminal. For sequence download, I introduce the rather new tool NCBI Databases.\n",
    "\n",
    "&#11157; [Open pathogenicity.ipynb](19_Pathogenicity/pathogenicity.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 20 – Virtual Sequencing of mtDNA\n",
    "\n",
    "Abstract This project focuses on virtually sequencing mitochondrial DNA, utilizing a template isolated from Homo sapiens neanderthalensis. Initial sequences are generated via a sequencing simulator, followed by assembly using the Velvet sequence assembler. Dot plots, generated by Dotter, serve as a crucial analytical tool for assessing the impact of diﬀerent sequencing parameters on assembly quality. Furthermore, BioAWK, a specialized version of AWK tailored for biological data analysis, is employed for eﬃcient manipulation and analysis of DNA sequences. Alongside, data visualization is conducted using R. The seamless integration of shell programming streamlines the execution of various tasks and tools. By leveraging these tools synergistically, this project aims to deepen understanding of DNA read handling, sequencing methodologies, and optimizing assembly processes.\n",
    "\n",
    "&#11157; [Open seq.ipynb](20_Sequencing/seq.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 21 – DNA Sequence Analysis of MinION Nanopore Reads\n",
    "\n",
    "Our project is dedicated to analyzing sequence reads from a plasmid following its digestion by either a restriction enzyme or a Cas9/gRNA complex. The aim is the identification of cutting sites within the plasmid. The reads were generated by DNA sequencing with a MinION, a pocket-sized sequencing device based on Nanopore technology. For the project, the FASTA5 read files are provided. The binary FASTA5 format standardizes nucleotide sequence data storage, ensuring compatibility across various bioinformatics tools. For the analysis, a suite of specialized tools is employed. The Guppy tool facilitates base calling and demultiplexing of nanopore sequence reads based on barcode identifiers. qfilter, a little tool developed in my lab, is utilized to filter sequencing data, retaining only high-quality reads while discarding noisy or low-quality data. The Minimap tool aligns long nucleotide sequences to a reference genome, facilitating the detection of similarities and diﬀerences relevant to cutting sites. This in turn is done with the Integrated Genome Viewer (IGV). Overall, the combined use of these tools enables the processing and analysis of MinION-derived sequencing data, ultimately leading to the identification of sequence features. Finally, the simulation of nanopore sequence reads is exemplified.\n",
    "\n",
    "&#11157; [Open minion.ipynb](21_NanoporeSeq/minion.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 22 – Querying for Potential Redox-Regulated Enzymes\n",
    "\n",
    "The focal point of this example lies within biochemistry, particularly the regulatory mechanisms of enzymes involving disulfide bond formation or cleavage near the protein surface. Thioredoxins, a group of proteins, play a pivotal role in catalyzing, e.g., reactions of the Calvin cycle. Interestingly, a comparison of primary structures reveals the absence of a consensus motif in most thioredoxin-regulated enzymes. To uncover potential enzyme targets for thioredoxin, the examination of protein structure data is essential. The approach in this project entails pinpointing cysteine sulfur atoms within a 3 Å radius, proximal to the surface. How is this achieved? We combine the power of Jmol, AWK, and shell programming. Essential to this quest is the need for an algorithm to compute the accessible surface area of macromolecules. Fortunately, Jmol boasts an integrated algorithm tailored for this purpose.\n",
    "\n",
    "&#11157; [Open thio.ipynb](22_Thioredoxin/thio.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 23 – Exploring Early SARS-CoV2 Mutations\n",
    "\n",
    "We have tackled the SARS-CoV-2 pandemic, but the lives lost were tragic. Our project delves into using bioinformatics tools to analyze mutations in the SARS-CoV-2 genome. Employed tools include IGV, SAMtools, BCFtools, Minimap, NCBI EDirect, AWK, and Jmol. IGV aids in visually inspecting genomic data for mutation identification. SAMtools and BCFtools process sequencing data to identify mutations from alignment (SAM/BAM) and variant call format (VCF) files. Minimap aligns SARS-CoV-2 sequences to a reference genome for mutation detection. NCBI EDirect retrieves SARS-CoV-2 sequences for mutation analysis. AWK filters and manipulates mutation data. Jmol visualizes the three-dimensional structure of SARS-CoV-2 spike proteins, aiding in understanding mutation implications. Integrating these tools enables comprehensive mutation analyses, oﬀering insights into viral evolution and impacts on disease strategies.\n",
    "\n",
    "&#11157; [Open sarscov2.ipynb](23_SARS-CoV-2/sarscov2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 24 – Genome-Wide Association Studies (GWAS)\n",
    "\n",
    "This project focuses on genome-wide association studies (GWAS), aiding in genetic test development for diseases. While human DNA sequences are mostly identical, variations can significantly influence disease risks, with single-nucleotide polymorphisms (SNPs) being key markers of such variations. SNPs occur in blocks on chromosomes, forming haplotypes. The HapMap project maps these blocks and simplifies genome examination. We analyze HapMap data of 90 Asian HapMap individuals with the PLINK software and create Manhattan plots with R.\n",
    "\n",
    "&#11157; [Open gwas.ipynb](24_GWAS/gwas.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
